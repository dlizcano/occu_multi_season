[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modelado de la Ocupación, abundancia y densidad de poblaciones",
    "section": "",
    "text": "Este es un curso de 4 horas parte del curso Modelado de la Ocupación, abundancia y densidad de poblaciones: enfoque frecuentista y bayesiano en R.\n\n\n\nRepaso del concepto de ocupación.\n\n\n\nRepaso de los modelos de ocupación de una temporada.\n\n\n\nModelo de ocupacion de multiples temporadas.\n\n\n\nComputador con acceso a Internet. Contar con R y RStudio previamente instalados. La instalación del programa no se explicará durante el curso.\nAntes del curso instalar los paquetes:\n\ncodigo R\ninstall.packages(\"tidyverse\")\ninstall.packages(\"sf\")\ninstall.packages(\"terra\")\ninstall.packages(\"mapview\")\ninstall.packages(\"elevatr\")\ninstall.packages(\"unmarked\")\n\nLa experiencia requerida en R es mínima, sin embargo, se espera que los participantes estén familiarizados con los objetos básicos de R: vectores, dataframes y listas. Asi como la forma de indexarlos. Puedes ver, aprender o repasar el manejo básico de R en este tutorial.\n\nTambién se requiere, un conocimiento básico sobre conceptos relacionados con mapas sistemas de coordenadas y proyecciones geográficas, aunque no es esencial."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Diego J. Lizcano, Ph.D.. Wildlife Conservation Society (WCS) y Sociedad Colombiana de Mastozoología (SCMas)"
  },
  {
    "objectID": "about.html#créditos",
    "href": "about.html#créditos",
    "title": "About",
    "section": "Créditos",
    "text": "Créditos\nEste mini curso es una parte del curso: Introducción al procesamiento, visualización y análisis de datos espaciales en R. coordinado por el Dr. Salvador Mandujano.\nCon este curso pretendemos presentar una introducción a los conceptos de monitoreo de biodiversidad usando modelos de ocupación, con estimadores de máxima verosimilitud y bayesianos.\nAlgunos ejercicios presentados en este curso fueron adaptados del taller - tutorial: Simulación y análisis de ocupación. Entendiendo las simulaciones y el modelo básico de ocupación."
  },
  {
    "objectID": "AM.html",
    "href": "AM.html",
    "title": "AM",
    "section": "",
    "text": "En primer lugar, es importante recordar que la organización es clave cuando se está generando un nuevo código. En este sentido, le recomendamos que cree una carpeta en su disco duro (C:) para cada nuevo proyecto. Puede hacer esto como un proyecto de Rstudio; para esto diríjase a: Archivo&gt; Nuevo proyecto o simplemente cree una nueva carpeta en su explorador y establezca su directorio de trabajo allí. Dentro de esta carpeta, cree una carpeta de datos donde guardará sus datos sin procesar. Puede almacenar algunos objetos intermedios en otra subcarpeta. También cree una carpeta para su código R y una carpeta para guardar sus figuras.\nla organización de carpetas que se sugere es:\nC://curso\n- data\n- R\n- fig\n\n\n\nDurante el curso utilizaremos datos que vamos a descargar de la plataforma GBIF con el paquete rgbif. El ejercicio lo haremos con una especie de mamífero amenazado, la danta de montaña (Tapirus pinchaque).\n\n\n\nDanta de montaña\n\n\n\nTenga en cuenta que se requiere conexión a internet y que podemos estar descargando muchos datos desde GBIF, así que este paso puede tardar unos segundos…\n\n\n\nCode\n#######################################\n## DOWNLOAD AND CLEAN DATA FROM GBIF ##\n#######################################\nlibrary(rgbif)\n# Si únicamente descargará los datos de una especie ----\nspecies1 &lt;- c(\"Tapirus pinchaque\")\n# Descargar datos de ocurrencia de GBIF para esta especie; Este proceso puede tomar tiempo si existen muchos puntos!\ngbif_data_sp1 &lt;- occ_data(scientificName = species1, hasCoordinate = TRUE, limit = 20000)\n# crear una tabla con los datos descargados:\ndat_sp1 &lt;- gbif_data_sp1$data\n# Si \"Records found\" es más grande que \"Records returned\", debe incrementar el argumento 'limit' arriba -- consulte help(occ_data) para ver opciones y limitaciones\n# Si la especie tiene una distribución amplia, pero usted desea trabajar en una región particular, puede descargar los datos para unas coordinadas particulares:\n\n\n# colombia_data &lt;- occ_data(scientificName = species1, hasCoordinate = TRUE, limit = 20000, decimalLatitude = \"0.996444, 5\")#decimalLongitude = \"-10, 10\", decimalLatitude = \"35, 55\")  # note que los intervalos de coordenadas deben estar especificadas en el siguiente formato: \"smaller, larger\" (e.g. \"-5, -2\")\n# gbif_data\n\n\nRevise el entorno global Global Environment, en donde ahora deben aparecer tres objetos en la memoria. Uno llamado myspecies que corresponde a la especie. Otro llamado “gbif_data” con los datos descargados del GBIF y el objeto “dat” que es una tabla que contiene los registros de la especie de interés.\n\n\n\nUna vez que la tabla esté cargada en el entorno global, es necesario hacer algunas verificaciones iniciales de los datos. Hay algunas funciones clave en R que nos permiten ver los datos de diferentes maneras. Es deseable que estas funciones se conviertan en una rutina estándar en sus scripts, pues le ayudarán a determinar si sus datos están formateados correctamente.\nPrimero, verificaremos el tipo de datos de cada una de las variables en nuestra tabla de datos. Tome un tiempo para entender cada una de estas variables.\n\n\nCode\n# ejecute una sola linea a la vez\nhead(dat_sp1) # ver los primeros seis registros de la tabla\ntail(dat_sp1) # ver los últimos seis registros de la tabla\n# ver los datos de la tabla\nView(dat_sp1) # ver toda la tabla\nnames(dat_sp1) # nombres de la columnas\nnrow(dat_sp1) # número de filas de la tabla\nncol(dat_sp1) # número de columnas de la tabla\nlength(unique(dat_sp1$stateProvince)) # número de categorías únicas de la columna \"stateProvince\"\nunique(dat_sp1$stateProvince) # categorías únicas de la columna \"stateProvince\"\nlength(unique(dat_sp1$year)) # número de categorías únicas de la columna \"stateProvince\"\nunique(dat_sp1$year) # años únicos de los registros\ntable(dat_sp1$publishingCountry) # número de registros por país\nsummary(dat_sp1) # resumen de la información disponible en la tabla\n\n\n\n\n\nOrdenar los datos significa manipularlos con el fin de facilitar su exploración y análisis. El paquete \"dplyr\", incluido en tidyverse, proporciona una serie de funciones útiles en este sentido. El marco conceptual que sustenta dplyr se llama “Gramática de la manipulación de datos”. A continuación revisaremos diferentes funciones para filtrar, resumir y combinar diferentes tablas.\n\n\nCode\n# cargar el paquete dplyr\nlibrary(dplyr)\n\n\n\n\n\nEmpecemos por explorar los datos para una región. Para ello, podemos utilizar la función filter, filtrando los datos de Risaralda, Quindío, Caldas y Tolima.\n\n\nCode\ndat_nevados &lt;- dplyr::filter(dat_sp1, stateProvince == c(\"Risaralda\", \"Quindío\", \"Caldas\", \"Tolima\")) \n\nhead(dat_nevados)\n\n\nTambién es posible que deseemos seleccionar solamente algunas columnas de nuestro conjunto de datos. Podemos hacer esto fácilmente con las herramientas de indexación de dataframes de R. En nuestro caso selecionaremos las columnas que son de nuestro interes.\n\n\nCode\n# get the columns that matter for mapping and cleaning the occurrence data:\nsp1_coords &lt;- gbif_data_sp1$data[ , c(\"scientificName\", \"decimalLongitude\", \"decimalLatitude\", \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n\nhead(sp1_coords) \n\n\n\n\n\nNuestra tabla de registros tiene información específica sobre las localidades de una sola especie. Con el fin de entender como combinar tablas descargaremos los datos de otra especie. En este caso el Oso Andino (Tremarctos ornatus).\n\n\n\nOso andino\n\n\n\nTenga en cuenta que se requiere conexión a internet y que podemos estar descargando muchos datos desde GBIF, así que este paso puede tardar unos segundos…\n\n\n\nCode\nspecies2 &lt;- c(\"Tremarctos ornatus\")\n# download GBIF occurrence data for this species; this takes time if there are many data points!\ngbif_data_sp2 &lt;- occ_data(scientificName = species2, hasCoordinate = TRUE, limit = 20000)\n# save to table\ndat_sp2 &lt;- gbif_data_sp2$data\n\n\nEl paquete dplyr proporciona un conjunto útil de funciones para unir tablas que tienen columnas en común. Escriba ?full_join en su consola y obtendrá una lista de todos los tipos de unión que admite dplyr.\nHoy usaremos full_join para unir los registros de dos especies en una sola tabla. La función full_join permite mantener las filas que no coinciden también). Otras funcionalidades de join se ven en la version ampliada de este curso.\n\n\nCode\ndat_oso_danta  &lt;- full_join(x = dat_sp2, y = dat_sp1)\n\n\n\n\n\nA menudo, es más fácil explorar datos mediante el uso de gráficos. R tiene buenos paquetes para realizar gráficos y visualizar datos. Hoy usaremos el paquete ggplot2.\n\n\nCode\nlibrary(ggplot2)\n\n\nPrimero, vamos a generar un histograma para revisar la distribución de los registos por año. Por ahora no nos preocuparemos demasiado por la estética de la gráfica.\n\n\nCode\nggplot(dat_oso_danta) + \n  aes(x = year) + \n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nEl componente ggplot(dat_input) determina la tabla de datos de la cual obtendremos las variables. Esta función también crea la página para el gráfico. El componente aes() hace referencia a la estética del gráfico, y aquí lo usamos para declarar que el eje x que corresponde a el año. Luego geom_histogram() declara el tipo de gráfico que se utilizará. En este caso se refiere al histograma.\nInténtelo de nuevo, pero esta vez añada un color para cada especie.\n\n\nCode\nggplot(dat_oso_danta) + \n  aes(x = year, fill = scientificName) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nVamos a graficar de nuevo los puntos de acuerdo a la especie. Para ello, incluya el argumento “color = scientificName” dentro de aes(). Observe que podemos ver que hay unos puntos que se comportan como outliers y debemos eliminarlos.\n\n\nCode\nggplot(dat_oso_danta) + \n  aes(x = decimalLongitude, y = decimalLatitude, color = scientificName) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nVamos a filtrar las dos especies de interes con la función filter()\n\n\nCode\ndat_oso_danta_filtrado &lt;- dat_oso_danta %&gt;% \n  filter(scientificName %in% c(\"Tremarctos ornatus (F.G.Cuvier, 1825)\", \"Tapirus pinchaque (Roulin, 1829)\")) %&gt;%\n  filter(decimalLatitude &lt;= 20 & decimalLatitude &gt;= -20)\n\n\nEn este caso, el operador %in% verifica cuáles elementos de la columna scientificName corresponden a las dos especies evaluadas. Es decir sirve para filtrar usando un vector. Observe que primero filtramos por las especies y luego por las coordenadas. Para ejecutar varios pasos como los anteriores, uno despues del otro podemos usar la función pipe %&gt;%, la cual permite utilizar el resultado de un paso como el primer argumento del siguiente.\nVeamos como queda\n\n\nCode\nggplot(dat_oso_danta_filtrado) + \n  aes(x = decimalLongitude, y = decimalLatitude, color = scientificName) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\nPresentar los datos en forma de gráficos es importante, pero ver los números concretos también puede ser útil. Supongamos que queremos identificar la elevación promedio y la desviación estándar a la que han sido recolectados los registros, así como el número de registros por departamento.\nPara hacer esto, vamos a agrupar los datos con la función group_by seguida de summarize para obtener las estadísticas en cada departamento.\n\n\nCode\ndatg &lt;- group_by(dat_oso_danta_filtrado, stateProvince)\n\n\ngroup_by() toma una tabla existente y la convierte en una tabla agrupada donde las operaciones se realizan “por grupo”. Revise el objeto datg y verá que los datos en sí mismos no han cambiado. Sin embargo, los datos están agrupados en 31 departamentos.\nAhora podemos utilizar esa tabla para resumir los datos con algunas estadísticas deseadas\n\n\nCode\ndat_elev_sum &lt;- \n    summarize(datg,\n              mean_elev = mean(elevation, na.rm=T),\n              sd_elev = sd(elevation, na.rm=T),\n              n = n())\n\ndat_elev_sum\n\n\n# A tibble: 68 × 4\n   stateProvince mean_elev sd_elev     n\n   &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;\n 1 Amazonas           NaN      NA     96\n 2 Ancash             NaN      NA     18\n 3 Antioquia         2062.    713.    30\n 4 Apurimac           NaN      NA     20\n 5 Ayacucho           NaN      NA      5\n 6 Azuay              NaN      NA      2\n 7 Bogotá, D.C.      2794      NA      1\n 8 Bolívar           1106.      0      3\n 9 Boyacá            2188.   1085.    69\n10 CaJamarca          NaN      NA      1\n# ℹ 58 more rows\n\n\nRecuerde que para ejecutar varios pasos, podemos usar la función %&gt;%, la cual permite utilizar el resultado de una función como el primer argumento del siguiente. Por ejemplo, estas líneas de código hacen lo mismo:\n\n\nCode\ngroup_by(dat_oso_danta_filtrado, stateProvince)\n#es lo mismo que\ndat_oso_danta_filtrado %&gt;% group_by(., stateProvince)\n\n\nLas función %&gt;% es muy útil para encadenar operaciones de varios pasos en tablas, lo que hace que nuestro código sea aún más fácil de entender y leer.\nAquí calculamos la desviación estándar y media de la elevación para cada departamento, así como el número de filas (registros) n () para cada departamento, pero antes hemos agrupado por especie.\n\n\nCode\ndat_elev_sum &lt;- \n  dat_oso_danta_filtrado %&gt;% \n  group_by(scientificName) %&gt;%\n  summarize(mean_elev  = mean(elevation, na.rm=T),\n            sd_elev = sd(elevation, na.rm=T),\n            n = n())\n\n\nAhora vamos a graficar la media y la desviación estándar de la elevación por especie:\n\n\nCode\ndat_oso_danta_filtrado %&gt;% \n  group_by(scientificName) %&gt;%\n  summarize(mean_elev  = mean(elevation, na.rm=T),\n            sd_elev = sd(elevation, na.rm=T),\n            n = n()) %&gt;%\n  ungroup() %&gt;%\n  ggplot(aes(x = scientificName, y = mean_elev)) +\n  geom_linerange(aes(ymin = mean_elev - sd_elev, ymax = mean_elev + sd_elev)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\nSupongamos que ahora queremos visualizar la distribución de registros a través del tiempo. Además, queremos ver la incidencia de diferentes técnicas de muestreo en el registro de especies. En primer lugar, necesitamos contar los registros por año.\n\n\nUtilice las funciones group_by, summarize y filter para contar los registros de cada especie por año desde 1950 por cada técnica de muestreo (basisOfRecord)\n\n\nCode\ndat_per_year&lt;-dat_oso_danta_filtrado %&gt;% \n                group_by(year,basisOfRecord) %&gt;%\n                summarize(n = n()) %&gt;%\n                filter(year &gt; 1949)\n\n\nAhora podemos graficar los datos agrupando por técnica de muestro\n\n\nCode\np1&lt;-ggplot(dat_per_year, aes(x=year, y=n,color = basisOfRecord)) +\n    geom_line(linewidth = 1) \np1\n\n\n\n\n\n\n\n\n\nAñadir una línea en que muestre el año con más registros\n\n\nCode\np2&lt;-p1 +\n  geom_vline(xintercept = 2016,colour=\"black\", linetype = \"longdash\") \np2\n\n\n\n\n\n\n\n\n\nLa función anotate() nos permite añadir texto en ubicaciones específicas de nuestro gráfico\n\n\nCode\np3&lt;-p2 +\n  annotate(\"text\", label = \"2016\", x = 2017, y = 1300, size = 4, colour = \"black\")\np3\n\n\n\n\n\n\n\n\n\nFinalmente, podemos cambiar el tamaño del texto de los ejes\n\n\nCode\ne1&lt;-p3 +\n  theme_bw()+\n  theme(legend.position = \"right\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14),\n        text = element_text(size = 14),\n        axis.text.x = element_text(size = 12),\n        axis.text.y = element_text(size = 12))+\n    ylab(\"# registros\")+ xlab(\"año\")+\n  ggtitle(\"Número de registros de danta y oso\")\ne1\n\n\n\n\n\n\n\n\n\n\n\n\n\nTenga en cuenta que es una buena practica citar correctamente los datos que se descargan de GBIF.\n\n\nCode\n# get the DOIs for citing these data properly:\n\ngbif_citation(gbif_data_sp1) # para la danta\n\ngbif_citation(gbif_data_sp2) # para la el oso\n\n# nota: si necesita o prefiere solo un DOI para todo el conjunto de datos, descargue el conjunto de datos directamente desde www.gbif.org y luego importe el .csv a R. ¡Es muy importante citar correctamente las fuentes de datos! GBIF no es una fuente, sólo un depósito para muchas personas que trabajaron muy duro para recopilar estos datos y ponerlos a disposición.\n\n\n¡Hemos llegado al final de la mañana! Los conceptos aprendidos el día de hoy serán fundamentales para sacar el mayor provecho en la tarde. Es hora de Almorzar :)"
  },
  {
    "objectID": "AM.html#caso-de-estudio",
    "href": "AM.html#caso-de-estudio",
    "title": "AM",
    "section": "",
    "text": "Durante el curso utilizaremos datos que vamos a descargar de la plataforma GBIF con el paquete rgbif. El ejercicio lo haremos con una especie de mamífero amenazado, la danta de montaña (Tapirus pinchaque).\n\n\n\nDanta de montaña\n\n\n\nTenga en cuenta que se requiere conexión a internet y que podemos estar descargando muchos datos desde GBIF, así que este paso puede tardar unos segundos…\n\n\n\nCode\n#######################################\n## DOWNLOAD AND CLEAN DATA FROM GBIF ##\n#######################################\nlibrary(rgbif)\n# Si únicamente descargará los datos de una especie ----\nspecies1 &lt;- c(\"Tapirus pinchaque\")\n# Descargar datos de ocurrencia de GBIF para esta especie; Este proceso puede tomar tiempo si existen muchos puntos!\ngbif_data_sp1 &lt;- occ_data(scientificName = species1, hasCoordinate = TRUE, limit = 20000)\n# crear una tabla con los datos descargados:\ndat_sp1 &lt;- gbif_data_sp1$data\n# Si \"Records found\" es más grande que \"Records returned\", debe incrementar el argumento 'limit' arriba -- consulte help(occ_data) para ver opciones y limitaciones\n# Si la especie tiene una distribución amplia, pero usted desea trabajar en una región particular, puede descargar los datos para unas coordinadas particulares:\n\n\n# colombia_data &lt;- occ_data(scientificName = species1, hasCoordinate = TRUE, limit = 20000, decimalLatitude = \"0.996444, 5\")#decimalLongitude = \"-10, 10\", decimalLatitude = \"35, 55\")  # note que los intervalos de coordenadas deben estar especificadas en el siguiente formato: \"smaller, larger\" (e.g. \"-5, -2\")\n# gbif_data\n\n\nRevise el entorno global Global Environment, en donde ahora deben aparecer tres objetos en la memoria. Uno llamado myspecies que corresponde a la especie. Otro llamado “gbif_data” con los datos descargados del GBIF y el objeto “dat” que es una tabla que contiene los registros de la especie de interés."
  },
  {
    "objectID": "AM.html#revisión-inicial-de-los-datos",
    "href": "AM.html#revisión-inicial-de-los-datos",
    "title": "AM",
    "section": "",
    "text": "Una vez que la tabla esté cargada en el entorno global, es necesario hacer algunas verificaciones iniciales de los datos. Hay algunas funciones clave en R que nos permiten ver los datos de diferentes maneras. Es deseable que estas funciones se conviertan en una rutina estándar en sus scripts, pues le ayudarán a determinar si sus datos están formateados correctamente.\nPrimero, verificaremos el tipo de datos de cada una de las variables en nuestra tabla de datos. Tome un tiempo para entender cada una de estas variables.\n\n\nCode\n# ejecute una sola linea a la vez\nhead(dat_sp1) # ver los primeros seis registros de la tabla\ntail(dat_sp1) # ver los últimos seis registros de la tabla\n# ver los datos de la tabla\nView(dat_sp1) # ver toda la tabla\nnames(dat_sp1) # nombres de la columnas\nnrow(dat_sp1) # número de filas de la tabla\nncol(dat_sp1) # número de columnas de la tabla\nlength(unique(dat_sp1$stateProvince)) # número de categorías únicas de la columna \"stateProvince\"\nunique(dat_sp1$stateProvince) # categorías únicas de la columna \"stateProvince\"\nlength(unique(dat_sp1$year)) # número de categorías únicas de la columna \"stateProvince\"\nunique(dat_sp1$year) # años únicos de los registros\ntable(dat_sp1$publishingCountry) # número de registros por país\nsummary(dat_sp1) # resumen de la información disponible en la tabla"
  },
  {
    "objectID": "AM.html#filtro-de-datos",
    "href": "AM.html#filtro-de-datos",
    "title": "AM",
    "section": "",
    "text": "Empecemos por explorar los datos para una región. Para ello, podemos utilizar la función filter, filtrando los datos de Risaralda, Quindío, Caldas y Tolima.\n\n\nCode\ndat_nevados &lt;- dplyr::filter(dat_sp1, stateProvince == c(\"Risaralda\", \"Quindío\", \"Caldas\", \"Tolima\")) \n\nhead(dat_nevados)\n\n\nTambién es posible que deseemos seleccionar solamente algunas columnas de nuestro conjunto de datos. Podemos hacer esto fácilmente con las herramientas de indexación de dataframes de R. En nuestro caso selecionaremos las columnas que son de nuestro interes.\n\n\nCode\n# get the columns that matter for mapping and cleaning the occurrence data:\nsp1_coords &lt;- gbif_data_sp1$data[ , c(\"scientificName\", \"decimalLongitude\", \"decimalLatitude\", \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n\nhead(sp1_coords)"
  },
  {
    "objectID": "AM.html#combinación-de-tablas",
    "href": "AM.html#combinación-de-tablas",
    "title": "AM",
    "section": "",
    "text": "Nuestra tabla de registros tiene información específica sobre las localidades de una sola especie. Con el fin de entender como combinar tablas descargaremos los datos de otra especie. En este caso el Oso Andino (Tremarctos ornatus).\n\n\n\nOso andino\n\n\n\nTenga en cuenta que se requiere conexión a internet y que podemos estar descargando muchos datos desde GBIF, así que este paso puede tardar unos segundos…\n\n\n\nCode\nspecies2 &lt;- c(\"Tremarctos ornatus\")\n# download GBIF occurrence data for this species; this takes time if there are many data points!\ngbif_data_sp2 &lt;- occ_data(scientificName = species2, hasCoordinate = TRUE, limit = 20000)\n# save to table\ndat_sp2 &lt;- gbif_data_sp2$data\n\n\nEl paquete dplyr proporciona un conjunto útil de funciones para unir tablas que tienen columnas en común. Escriba ?full_join en su consola y obtendrá una lista de todos los tipos de unión que admite dplyr.\nHoy usaremos full_join para unir los registros de dos especies en una sola tabla. La función full_join permite mantener las filas que no coinciden también). Otras funcionalidades de join se ven en la version ampliada de este curso.\n\n\nCode\ndat_oso_danta  &lt;- full_join(x = dat_sp2, y = dat_sp1)"
  },
  {
    "objectID": "PM.html",
    "href": "PM.html",
    "title": "PM",
    "section": "",
    "text": "Comenzamos cargando tres paquetes básicos necesarios para generar nuestros primeros mapas; mapview, sf y ggplot2.\n\n\nCode\nlibrary(mapview)\nlibrary(ggplot2)\nlibrary(sf)\n\n\nEl paquete sf se utiliza para trabajar con datos espaciales y ofrece funciones para leer, escribir y analizar datos espaciales (features en inglés) de una manera sencilla y eficiente.\nTambién utilizaremos el paquete maps para cargar un mapa global. Existen otros paquetes que también funcionan para este propósito, como el paquete rnaturalearth, el cual proporciona un mapa de países de todo el mundo.\n\n\nCode\nlibrary(maps)\n\n\nAhora podemos cargar el mapa global usando la función map(). Además, transformaremos el objeto world a un simple feature o sf, este representa características simples como registros en un data.frame o tibble (tabla) con una lista-columna de geometrías (punto, linea, poligono, etc) que representan la forma, mas un sistema de coordendas.\n\n\nCode\nworld1 &lt;- sf::st_as_sf(map(database = 'world', plot = FALSE, fill = TRUE))\nworld1\n\n\nSimple feature collection with 253 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -85.19218 xmax: 190.2708 ymax: 83.59961\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\nFirst 10 features:\n                                       ID                           geom\nAruba                               Aruba MULTIPOLYGON (((-69.89912 1...\nAfghanistan                   Afghanistan MULTIPOLYGON (((74.89131 37...\nAngola                             Angola MULTIPOLYGON (((23.9665 -10...\nAnguilla                         Anguilla MULTIPOLYGON (((-63.00122 1...\nAlbania                           Albania MULTIPOLYGON (((20.06396 42...\nFinland                           Finland MULTIPOLYGON (((20.61133 60...\nAndorra                           Andorra MULTIPOLYGON (((1.706055 42...\nUnited Arab Emirates United Arab Emirates MULTIPOLYGON (((53.92783 24...\nArgentina                       Argentina MULTIPOLYGON (((-64.54916 -...\nArmenia                           Armenia MULTIPOLYGON (((45.55235 40...\n\n\nEjercicio\nIdentifique las principales características del objeto world1:\n¿Cuántos atributos y polígonos tiene? ¿Cuál es el sistema de coordenadas? ¿Cuál es su extensión?\nEjecicio extra ¿Cómo reescribiría la función anterior utilizando %&gt;% ?\nAhora veamos el objeto world1 usando la función plot\n\n\nCode\nplot(world1)\n\n\n\n\n\n\n\n\n\nAhora podemos generar un plot utilizando el paquete ggplot y los conceptos aprendidos durante la sesión anterior.\nEn este caso, debemos utilizar geom_sf() con el fin de llamar nuestro objeto sf\n\n\nCode\nggplot() +\n  geom_sf(data = world1) \n\n\n\n\n\n\n\n\n\nEl siguiente paso consiste en anadir puntos de distribución de especies sobre nuestro mapa. Para ello, vamos a utilizar los puntos de localidades descargados desde GBIF en la mañana.\n\n\nCode\nlibrary(tidyverse)\n\n\nPara añadir los puntos en nuestro mapa, utilizaremos la función geom_point()\n\n\nCode\nggplot() +\n  geom_sf(data = world1) +\n  geom_point(data = dat_oso_danta_filtrado, aes(x = decimalLongitude, y = decimalLatitude))\n\n\n\n\n\n\n\n\n\nNote que hemos utilizado ggplot() sin algún argumento dentro de los corchetes. Esto se debe a que trazamos varias capas, cada una con una fuente de datos diferente, por lo que debemos especificar los datos proporcionados a cada geom por separado (data = world1 para geom_sf() y data = dat para geom_point()).\nEste mapa se ve bien, pero no es necesario que representemos al mundo entero aquí. Por lo tanto, podemos modificar nuestro mapa estableciendo límites en las coordenadas. Además, podemos cambiar los colores de nuestros objetos.\nEn primer lugar, necesitamos definir la extensión de nuestros puntos\n\n\nCode\nrange(dat_oso_danta_filtrado$decimalLongitude)\n\n\n[1] -79.8566 -65.9310\n\n\nCode\nrange(dat_oso_danta_filtrado$decimalLatitude)\n\n\n[1] -17.39878  10.67390\n\n\nEstos son los valores que utilizaremos de guía para definir la extensión de nuestro mapa mediante el uso de coord_sf(). Note que vamos a añadir los argumentos xlim y ylim que definen el limite de nuestro mapa\nEl nuevo mapa con la extensión corregida luce de la siguiente manera:\n\n\nCode\nggplot() +\n  geom_sf(data = world1) +\n  geom_point(data = dat_oso_danta_filtrado, aes(x = decimalLongitude, y = decimalLatitude)) +\n  coord_sf(xlim = c(-79.8566, -65.9310), ylim =  c(-17.39878, 10.67390)) +\n  labs(y = \"latitude\", x = \"longitude\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nEjercicio\nGenere el mismo mapa pero esta vez coloree los puntos de acuerdo a la especie. Además, cambie el color de los países a verde usando la siguiente opción:\ncolor = “black”, fill = “lightgreen”\n\n\n\n\n\n\n\n\n\nHasta acá hemos aprendido un vistazo general sobre las caracteristicas vectoriales (puntos, lineas, poligonos) de los mapas. Sin embargo, gran parte de los mapas tienen otro tipo de informacion que no es vectorial.\n\n\n\nUn ráster es una estructura de datos espaciales (geográficos) que divide una región en rectángulos llamados “celdas” (o “píxeles”) que pueden almacenar uno o más valores para cada una de estas celdas. Esta estructura de datos también se conoce como “cuadrícula” (o grid) y a contrasta con los datos “vectoriales” que se utilizan para representar puntos, líneas y polígonos.\nLos objetos ráster, se pueden leer y manipular con el paquete terra. Carguemos ese paquete ahora:\n\n\nCode\nlibrary(terra)\n\n\nLa función terra() nos sirve para cargar y manipular objetos raster dentro de R.\nPara este ejercicio vamos a descargar un modelo digital de elevación de terreno (DEM) usando el paquete elevatr, el cual descarga la topografia desde Amazon Web Services (AWS). Como fuente podemos usar cualquier mapa sf, en nuestro caso usaremos el mapa de puntos de la danta y el oso el cual convertiremos a sf.\nEn este caso, cargaremos una capa de elevación para el territorio colombiano.\n\n\nCode\n# definir CRS\nprojlatlon &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n# convertir tabla de puntos a sf\ndanta_oso_sf &lt;- st_as_sf(x = dat_oso_danta_filtrado,\n                         coords = c(\"decimalLongitude\", \"decimalLatitude\"),\n                            crs = projlatlon)\n\nlibrary(elevatr)\nelevation &lt;- get_elev_raster(danta_oso_sf, z=4) # z define el nivel de zoom \nterra::plot(elevation)\n\n\n\n\n\n\n\n\n\nTome un tiempo para inspeccionar las principales características del raster, incluyendo su resolución y extensión.\nLa función plot() del paquete raster crea una primera gráfica bastante decente. Sin embargo, tenga en cuenta que la escala de colores no es tan apropiada para las elevaciones: verde donde las elevaciones son altas y rojo donde son bajas. Además, estos colores predeterminados no serían tan buenos si nuestra audiencia no pudiese ver el color rojo-verde.\nVamos entonces a crear el gráfico anterior usando ggplot. Antes de esto, necesitamos convertir el ráster en una tabla:\n\n\nCode\ndat_grid &lt;- \n  data.frame(xyFromCell(elevation, 1:ncell(elevation)),\n             vals = elevation[]) %&gt;%\n  as_tibble()\nhead(dat_grid)\n\n\n# A tibble: 6 × 3\n      x     y  vals\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 -90.0  21.9   -39\n2 -89.9  21.9   -38\n3 -89.9  21.9   -39\n4 -89.8  21.9   -39\n5 -89.8  21.9   -39\n6 -89.8  21.9   -39\n\n\nAhora podemos incluir el raster en nuestro mapa utilizando la función geom_tile()\n\n\nCode\nggplot() +\n  geom_tile(data = dat_grid, aes(x = x, y = y, fill = vals)) +\n  geom_sf(data = world1, color = \"black\", fill = NA) +\n  geom_sf(data = danta_oso_sf, aes(color = scientificName)) +\n  coord_sf(xlim = c(-80, -49), ylim =  c(-13.5, 13)) +\n  labs(y = \"latitude\", x = \"longitude\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nPodemos mejorar el mapa anterior cambiando el azul por gris\n\n\nCode\nggplot() +\n  geom_tile(data = dat_grid, aes(x = x, y = y, fill = vals)) +\n  scale_fill_distiller(type = \"seq\", palette = \"Greys\",\n                        direction = 1) +\n  geom_sf(data = world1, color = \"black\", fill = NA) +\n  geom_sf(data = danta_oso_sf, aes(color = scientificName)) +\n  coord_sf(xlim = c(-80, -49), ylim =  c(-13.5, 13)) +\n  labs(y = \"latitude\", x = \"longitude\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nLa función terrain nos permite obtener mapas de la pendiente, el aspecto y la rugosidad, los cuales usaremos mas adelante.\n\n\nCode\nterreno &lt;- terrain(elevation, c( \"slope\", \"aspect\", \"roughness\"))\nterreno # nuevo objeto con varios raster\n\n\nclass      : RasterBrick \ndimensions : 1011, 1037, 1048407, 3  (nrow, ncol, ncell, nlayers)\nresolution : 0.04340482, 0.04340482  (x, y)\nextent     : -90, -44.9892, -21.93923, 21.94305  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : memory\nnames      :    roughness,        slope,       aspect \nmin values :            0,            0,            0 \nmax values : 4453.0000000,    0.3837085,    6.2831853 \n\n\nCode\nplot (terreno)"
  },
  {
    "objectID": "PM.html#extraer-datos-de-un-raster-basados-en-un-sf",
    "href": "PM.html#extraer-datos-de-un-raster-basados-en-un-sf",
    "title": "PM",
    "section": "Extraer datos de un raster basados en un sf",
    "text": "Extraer datos de un raster basados en un sf\n\n\nCode\ncovariables&lt;- terra::extract (terreno, danta_oso_sf)\nhead(covariables)\n\n\n     roughness      slope     aspect\n[1,]       307 0.01862192 0.01528054\n[2,]       413 0.02138133 4.85660231\n[3,]       472 0.03176053 1.06784213\n[4,]       476 0.03902415 5.74084536\n[5,]       884 0.07371204 6.06315362\n[6,]       890 0.06135130 2.03976466\n\n\nAhora adicionemos la informacion de la especie.\n\n\nCode\ndat_mamm&lt;-cbind(covariables, danta_oso_sf$scientificName)\nsummary(dat_mamm)"
  },
  {
    "objectID": "PM.html#graficas-adicionales",
    "href": "PM.html#graficas-adicionales",
    "title": "PM",
    "section": "graficas adicionales",
    "text": "graficas adicionales\nEjercicio\nGenere un histograma mostrando la distribución de la pendiente y la rugosidad para los registros de cada especie."
  },
  {
    "objectID": "PM.html#obtenga-ayuda",
    "href": "PM.html#obtenga-ayuda",
    "title": "PM",
    "section": "Obtenga ayuda",
    "text": "Obtenga ayuda\nEscribir código consiste en ensayo error y un 90% buscar la respuesta en Google.\nSi busca un problema en la web, como “ggplot remove legend”, normalmente obtendrá una respuesta bastante decente en Stack Overflow o en un sitio similar.\nSi la respuesta aún no existe en línea, regístrese en Stack Overflow y pregúntela usted mismo (pero primer dedique tiempo suficiente en buscar … ¡nadie quiere ser etiquetado por duplicar una pregunta existente!).\nOtra buena idea es buscar un grupo de apoyo local. El uso de R es una experiencia emocional, la curva de aprendizaje al comienzo es bien empinada, la frustración es común, pero luego de un tiempo la alegría de encontrar una solución puede ayudarnos a persistir. Tener a otras personas para ayudar, o simplemente escuchar sus frustraciones es una gran motivación para seguir aprendiendo R."
  },
  {
    "objectID": "index.html#estructura-del-curso",
    "href": "index.html#estructura-del-curso",
    "title": "Modelado de la Ocupación, abundancia y densidad de poblaciones",
    "section": "",
    "text": "Este es un curso de 4 horas parte del curso Modelado de la Ocupación, abundancia y densidad de poblaciones: enfoque frecuentista y bayesiano en R.\n\n\n\nRepaso del concepto de ocupación.\n\n\n\nRepaso de los modelos de ocupación de una temporada.\n\n\n\nModelo de ocupacion de multiples temporadas.\n\n\n\nComputador con acceso a Internet. Contar con R y RStudio previamente instalados. La instalación del programa no se explicará durante el curso.\nAntes del curso instalar los paquetes:\n\ncodigo R\ninstall.packages(\"tidyverse\")\ninstall.packages(\"sf\")\ninstall.packages(\"terra\")\ninstall.packages(\"mapview\")\ninstall.packages(\"elevatr\")\ninstall.packages(\"unmarked\")\n\nLa experiencia requerida en R es mínima, sin embargo, se espera que los participantes estén familiarizados con los objetos básicos de R: vectores, dataframes y listas. Asi como la forma de indexarlos. Puedes ver, aprender o repasar el manejo básico de R en este tutorial.\n\nTambién se requiere, un conocimiento básico sobre conceptos relacionados con mapas sistemas de coordenadas y proyecciones geográficas, aunque no es esencial."
  },
  {
    "objectID": "PM.html#creación-de-un-mapa-básico-en-r",
    "href": "PM.html#creación-de-un-mapa-básico-en-r",
    "title": "PM",
    "section": "",
    "text": "Comenzamos cargando tres paquetes básicos necesarios para generar nuestros primeros mapas; mapview, sf y ggplot2.\n\n\nCode\nlibrary(mapview)\nlibrary(ggplot2)\nlibrary(sf)\n\n\nEl paquete sf se utiliza para trabajar con datos espaciales y ofrece funciones para leer, escribir y analizar datos espaciales (features en inglés) de una manera sencilla y eficiente.\nTambién utilizaremos el paquete maps para cargar un mapa global. Existen otros paquetes que también funcionan para este propósito, como el paquete rnaturalearth, el cual proporciona un mapa de países de todo el mundo.\n\n\nCode\nlibrary(maps)\n\n\nAhora podemos cargar el mapa global usando la función map(). Además, transformaremos el objeto world a un simple feature o sf, este representa características simples como registros en un data.frame o tibble (tabla) con una lista-columna de geometrías (punto, linea, poligono, etc) que representan la forma, mas un sistema de coordendas.\n\n\nCode\nworld1 &lt;- sf::st_as_sf(map(database = 'world', plot = FALSE, fill = TRUE))\nworld1\n\n\nSimple feature collection with 253 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -85.19218 xmax: 190.2708 ymax: 83.59961\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\nFirst 10 features:\n                                       ID                           geom\nAruba                               Aruba MULTIPOLYGON (((-69.89912 1...\nAfghanistan                   Afghanistan MULTIPOLYGON (((74.89131 37...\nAngola                             Angola MULTIPOLYGON (((23.9665 -10...\nAnguilla                         Anguilla MULTIPOLYGON (((-63.00122 1...\nAlbania                           Albania MULTIPOLYGON (((20.06396 42...\nFinland                           Finland MULTIPOLYGON (((20.61133 60...\nAndorra                           Andorra MULTIPOLYGON (((1.706055 42...\nUnited Arab Emirates United Arab Emirates MULTIPOLYGON (((53.92783 24...\nArgentina                       Argentina MULTIPOLYGON (((-64.54916 -...\nArmenia                           Armenia MULTIPOLYGON (((45.55235 40...\n\n\nEjercicio\nIdentifique las principales características del objeto world1:\n¿Cuántos atributos y polígonos tiene? ¿Cuál es el sistema de coordenadas? ¿Cuál es su extensión?\nEjecicio extra ¿Cómo reescribiría la función anterior utilizando %&gt;% ?\nAhora veamos el objeto world1 usando la función plot\n\n\nCode\nplot(world1)\n\n\n\n\n\n\n\n\n\nAhora podemos generar un plot utilizando el paquete ggplot y los conceptos aprendidos durante la sesión anterior.\nEn este caso, debemos utilizar geom_sf() con el fin de llamar nuestro objeto sf\n\n\nCode\nggplot() +\n  geom_sf(data = world1) \n\n\n\n\n\n\n\n\n\nEl siguiente paso consiste en anadir puntos de distribución de especies sobre nuestro mapa. Para ello, vamos a utilizar los puntos de localidades descargados desde GBIF en la mañana.\n\n\nCode\nlibrary(tidyverse)\n\n\nPara añadir los puntos en nuestro mapa, utilizaremos la función geom_point()\n\n\nCode\nggplot() +\n  geom_sf(data = world1) +\n  geom_point(data = dat_oso_danta_filtrado, aes(x = decimalLongitude, y = decimalLatitude))\n\n\n\n\n\n\n\n\n\nNote que hemos utilizado ggplot() sin algún argumento dentro de los corchetes. Esto se debe a que trazamos varias capas, cada una con una fuente de datos diferente, por lo que debemos especificar los datos proporcionados a cada geom por separado (data = world1 para geom_sf() y data = dat para geom_point()).\nEste mapa se ve bien, pero no es necesario que representemos al mundo entero aquí. Por lo tanto, podemos modificar nuestro mapa estableciendo límites en las coordenadas. Además, podemos cambiar los colores de nuestros objetos.\nEn primer lugar, necesitamos definir la extensión de nuestros puntos\n\n\nCode\nrange(dat_oso_danta_filtrado$decimalLongitude)\n\n\n[1] -79.8566 -65.9310\n\n\nCode\nrange(dat_oso_danta_filtrado$decimalLatitude)\n\n\n[1] -17.39878  10.67390\n\n\nEstos son los valores que utilizaremos de guía para definir la extensión de nuestro mapa mediante el uso de coord_sf(). Note que vamos a añadir los argumentos xlim y ylim que definen el limite de nuestro mapa\nEl nuevo mapa con la extensión corregida luce de la siguiente manera:\n\n\nCode\nggplot() +\n  geom_sf(data = world1) +\n  geom_point(data = dat_oso_danta_filtrado, aes(x = decimalLongitude, y = decimalLatitude)) +\n  coord_sf(xlim = c(-79.8566, -65.9310), ylim =  c(-17.39878, 10.67390)) +\n  labs(y = \"latitude\", x = \"longitude\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nEjercicio\nGenere el mismo mapa pero esta vez coloree los puntos de acuerdo a la especie. Además, cambie el color de los países a verde usando la siguiente opción:\ncolor = “black”, fill = “lightgreen”\n\n\n\n\n\n\n\n\n\nHasta acá hemos aprendido un vistazo general sobre las caracteristicas vectoriales (puntos, lineas, poligonos) de los mapas. Sin embargo, gran parte de los mapas tienen otro tipo de informacion que no es vectorial."
  },
  {
    "objectID": "PM.html#objetos-raster",
    "href": "PM.html#objetos-raster",
    "title": "PM",
    "section": "",
    "text": "Un ráster es una estructura de datos espaciales (geográficos) que divide una región en rectángulos llamados “celdas” (o “píxeles”) que pueden almacenar uno o más valores para cada una de estas celdas. Esta estructura de datos también se conoce como “cuadrícula” (o grid) y a contrasta con los datos “vectoriales” que se utilizan para representar puntos, líneas y polígonos.\nLos objetos ráster, se pueden leer y manipular con el paquete terra. Carguemos ese paquete ahora:\n\n\nCode\nlibrary(terra)\n\n\nLa función terra() nos sirve para cargar y manipular objetos raster dentro de R.\nPara este ejercicio vamos a descargar un modelo digital de elevación de terreno (DEM) usando el paquete elevatr, el cual descarga la topografia desde Amazon Web Services (AWS). Como fuente podemos usar cualquier mapa sf, en nuestro caso usaremos el mapa de puntos de la danta y el oso el cual convertiremos a sf.\nEn este caso, cargaremos una capa de elevación para el territorio colombiano.\n\n\nCode\n# definir CRS\nprojlatlon &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n# convertir tabla de puntos a sf\ndanta_oso_sf &lt;- st_as_sf(x = dat_oso_danta_filtrado,\n                         coords = c(\"decimalLongitude\", \"decimalLatitude\"),\n                            crs = projlatlon)\n\nlibrary(elevatr)\nelevation &lt;- get_elev_raster(danta_oso_sf, z=4) # z define el nivel de zoom \nterra::plot(elevation)\n\n\n\n\n\n\n\n\n\nTome un tiempo para inspeccionar las principales características del raster, incluyendo su resolución y extensión.\nLa función plot() del paquete raster crea una primera gráfica bastante decente. Sin embargo, tenga en cuenta que la escala de colores no es tan apropiada para las elevaciones: verde donde las elevaciones son altas y rojo donde son bajas. Además, estos colores predeterminados no serían tan buenos si nuestra audiencia no pudiese ver el color rojo-verde.\nVamos entonces a crear el gráfico anterior usando ggplot. Antes de esto, necesitamos convertir el ráster en una tabla:\n\n\nCode\ndat_grid &lt;- \n  data.frame(xyFromCell(elevation, 1:ncell(elevation)),\n             vals = elevation[]) %&gt;%\n  as_tibble()\nhead(dat_grid)\n\n\n# A tibble: 6 × 3\n      x     y  vals\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 -90.0  21.9   -39\n2 -89.9  21.9   -38\n3 -89.9  21.9   -39\n4 -89.8  21.9   -39\n5 -89.8  21.9   -39\n6 -89.8  21.9   -39\n\n\nAhora podemos incluir el raster en nuestro mapa utilizando la función geom_tile()\n\n\nCode\nggplot() +\n  geom_tile(data = dat_grid, aes(x = x, y = y, fill = vals)) +\n  geom_sf(data = world1, color = \"black\", fill = NA) +\n  geom_sf(data = danta_oso_sf, aes(color = scientificName)) +\n  coord_sf(xlim = c(-80, -49), ylim =  c(-13.5, 13)) +\n  labs(y = \"latitude\", x = \"longitude\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nPodemos mejorar el mapa anterior cambiando el azul por gris\n\n\nCode\nggplot() +\n  geom_tile(data = dat_grid, aes(x = x, y = y, fill = vals)) +\n  scale_fill_distiller(type = \"seq\", palette = \"Greys\",\n                        direction = 1) +\n  geom_sf(data = world1, color = \"black\", fill = NA) +\n  geom_sf(data = danta_oso_sf, aes(color = scientificName)) +\n  coord_sf(xlim = c(-80, -49), ylim =  c(-13.5, 13)) +\n  labs(y = \"latitude\", x = \"longitude\") +\n  theme_bw()"
  },
  {
    "objectID": "PM.html#rasters-derivados",
    "href": "PM.html#rasters-derivados",
    "title": "PM",
    "section": "",
    "text": "La función terrain nos permite obtener mapas de la pendiente, el aspecto y la rugosidad, los cuales usaremos mas adelante.\n\n\nCode\nterreno &lt;- terrain(elevation, c( \"slope\", \"aspect\", \"roughness\"))\nterreno # nuevo objeto con varios raster\n\n\nclass      : RasterBrick \ndimensions : 1011, 1037, 1048407, 3  (nrow, ncol, ncell, nlayers)\nresolution : 0.04340482, 0.04340482  (x, y)\nextent     : -90, -44.9892, -21.93923, 21.94305  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : memory\nnames      :    roughness,        slope,       aspect \nmin values :            0,            0,            0 \nmax values : 4453.0000000,    0.3837085,    6.2831853 \n\n\nCode\nplot (terreno)"
  },
  {
    "objectID": "PM.html#gráficas-adicionales",
    "href": "PM.html#gráficas-adicionales",
    "title": "PM",
    "section": "Gráficas adicionales",
    "text": "Gráficas adicionales\nEjercicio\nGenere un histograma mostrando la distribución de la pendiente y la rugosidad para los registros de cada especie."
  },
  {
    "objectID": "about.html#instructores",
    "href": "about.html#instructores",
    "title": "About",
    "section": "",
    "text": "Diego J. Lizcano, Ph.D. Sociedad Colombiana de Mastozoología (SCMas)\nAndres Felipe Suárez-Castro, Ph.D. Griffith University: Brisbane, Australia."
  },
  {
    "objectID": "AM.html#datos-y-organización-general",
    "href": "AM.html#datos-y-organización-general",
    "title": "AM",
    "section": "",
    "text": "En primer lugar, es importante recordar que la organización es clave cuando se está generando un nuevo código. En este sentido, le recomendamos que cree una carpeta en su disco duro (C:) para cada nuevo proyecto. Puede hacer esto como un proyecto de Rstudio; para esto diríjase a: Archivo&gt; Nuevo proyecto o simplemente cree una nueva carpeta en su explorador y establezca su directorio de trabajo allí. Dentro de esta carpeta, cree una carpeta de datos donde guardará sus datos sin procesar. Puede almacenar algunos objetos intermedios en otra subcarpeta. También cree una carpeta para su código R y una carpeta para guardar sus figuras.\nla organización de carpetas que se sugere es:\nC://curso\n- data\n- R\n- fig"
  },
  {
    "objectID": "AM.html#ordenamiento-de-datos",
    "href": "AM.html#ordenamiento-de-datos",
    "title": "AM",
    "section": "",
    "text": "Ordenar los datos significa manipularlos con el fin de facilitar su exploración y análisis. El paquete \"dplyr\", incluido en tidyverse, proporciona una serie de funciones útiles en este sentido. El marco conceptual que sustenta dplyr se llama “Gramática de la manipulación de datos”. A continuación revisaremos diferentes funciones para filtrar, resumir y combinar diferentes tablas.\n\n\nCode\n# cargar el paquete dplyr\nlibrary(dplyr)"
  },
  {
    "objectID": "AM.html#visualización-de-datos",
    "href": "AM.html#visualización-de-datos",
    "title": "AM",
    "section": "",
    "text": "A menudo, es más fácil explorar datos mediante el uso de gráficos. R tiene buenos paquetes para realizar gráficos y visualizar datos. Hoy usaremos el paquete ggplot2.\n\n\nCode\nlibrary(ggplot2)\n\n\nPrimero, vamos a generar un histograma para revisar la distribución de los registos por año. Por ahora no nos preocuparemos demasiado por la estética de la gráfica.\n\n\nCode\nggplot(dat_oso_danta) + \n  aes(x = year) + \n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nEl componente ggplot(dat_input) determina la tabla de datos de la cual obtendremos las variables. Esta función también crea la página para el gráfico. El componente aes() hace referencia a la estética del gráfico, y aquí lo usamos para declarar que el eje x que corresponde a el año. Luego geom_histogram() declara el tipo de gráfico que se utilizará. En este caso se refiere al histograma.\nInténtelo de nuevo, pero esta vez añada un color para cada especie.\n\n\nCode\nggplot(dat_oso_danta) + \n  aes(x = year, fill = scientificName) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nVamos a graficar de nuevo los puntos de acuerdo a la especie. Para ello, incluya el argumento “color = scientificName” dentro de aes(). Observe que podemos ver que hay unos puntos que se comportan como outliers y debemos eliminarlos.\n\n\nCode\nggplot(dat_oso_danta) + \n  aes(x = decimalLongitude, y = decimalLatitude, color = scientificName) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nVamos a filtrar las dos especies de interes con la función filter()\n\n\nCode\ndat_oso_danta_filtrado &lt;- dat_oso_danta %&gt;% \n  filter(scientificName %in% c(\"Tremarctos ornatus (F.G.Cuvier, 1825)\", \"Tapirus pinchaque (Roulin, 1829)\")) %&gt;%\n  filter(decimalLatitude &lt;= 20 & decimalLatitude &gt;= -20)\n\n\nEn este caso, el operador %in% verifica cuáles elementos de la columna scientificName corresponden a las dos especies evaluadas. Es decir sirve para filtrar usando un vector. Observe que primero filtramos por las especies y luego por las coordenadas. Para ejecutar varios pasos como los anteriores, uno despues del otro podemos usar la función pipe %&gt;%, la cual permite utilizar el resultado de un paso como el primer argumento del siguiente.\nVeamos como queda\n\n\nCode\nggplot(dat_oso_danta_filtrado) + \n  aes(x = decimalLongitude, y = decimalLatitude, color = scientificName) +\n  geom_point()"
  },
  {
    "objectID": "AM.html#agrupación-y-resumen-de-datos",
    "href": "AM.html#agrupación-y-resumen-de-datos",
    "title": "AM",
    "section": "",
    "text": "Presentar los datos en forma de gráficos es importante, pero ver los números concretos también puede ser útil. Supongamos que queremos identificar la elevación promedio y la desviación estándar a la que han sido recolectados los registros, así como el número de registros por departamento.\nPara hacer esto, vamos a agrupar los datos con la función group_by seguida de summarize para obtener las estadísticas en cada departamento.\n\n\nCode\ndatg &lt;- group_by(dat_oso_danta_filtrado, stateProvince)\n\n\ngroup_by() toma una tabla existente y la convierte en una tabla agrupada donde las operaciones se realizan “por grupo”. Revise el objeto datg y verá que los datos en sí mismos no han cambiado. Sin embargo, los datos están agrupados en 31 departamentos.\nAhora podemos utilizar esa tabla para resumir los datos con algunas estadísticas deseadas\n\n\nCode\ndat_elev_sum &lt;- \n    summarize(datg,\n              mean_elev = mean(elevation, na.rm=T),\n              sd_elev = sd(elevation, na.rm=T),\n              n = n())\n\ndat_elev_sum\n\n\n# A tibble: 68 × 4\n   stateProvince mean_elev sd_elev     n\n   &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;\n 1 Amazonas           NaN      NA     96\n 2 Ancash             NaN      NA     18\n 3 Antioquia         2062.    713.    30\n 4 Apurimac           NaN      NA     20\n 5 Ayacucho           NaN      NA      5\n 6 Azuay              NaN      NA      2\n 7 Bogotá, D.C.      2794      NA      1\n 8 Bolívar           1106.      0      3\n 9 Boyacá            2188.   1085.    69\n10 CaJamarca          NaN      NA      1\n# ℹ 58 more rows\n\n\nRecuerde que para ejecutar varios pasos, podemos usar la función %&gt;%, la cual permite utilizar el resultado de una función como el primer argumento del siguiente. Por ejemplo, estas líneas de código hacen lo mismo:\n\n\nCode\ngroup_by(dat_oso_danta_filtrado, stateProvince)\n#es lo mismo que\ndat_oso_danta_filtrado %&gt;% group_by(., stateProvince)\n\n\nLas función %&gt;% es muy útil para encadenar operaciones de varios pasos en tablas, lo que hace que nuestro código sea aún más fácil de entender y leer.\nAquí calculamos la desviación estándar y media de la elevación para cada departamento, así como el número de filas (registros) n () para cada departamento, pero antes hemos agrupado por especie.\n\n\nCode\ndat_elev_sum &lt;- \n  dat_oso_danta_filtrado %&gt;% \n  group_by(scientificName) %&gt;%\n  summarize(mean_elev  = mean(elevation, na.rm=T),\n            sd_elev = sd(elevation, na.rm=T),\n            n = n())\n\n\nAhora vamos a graficar la media y la desviación estándar de la elevación por especie:\n\n\nCode\ndat_oso_danta_filtrado %&gt;% \n  group_by(scientificName) %&gt;%\n  summarize(mean_elev  = mean(elevation, na.rm=T),\n            sd_elev = sd(elevation, na.rm=T),\n            n = n()) %&gt;%\n  ungroup() %&gt;%\n  ggplot(aes(x = scientificName, y = mean_elev)) +\n  geom_linerange(aes(ymin = mean_elev - sd_elev, ymax = mean_elev + sd_elev)) +\n  geom_point()"
  },
  {
    "objectID": "AM.html#creación-de-plots-para-publicaciones",
    "href": "AM.html#creación-de-plots-para-publicaciones",
    "title": "AM",
    "section": "",
    "text": "Supongamos que ahora queremos visualizar la distribución de registros a través del tiempo. Además, queremos ver la incidencia de diferentes técnicas de muestreo en el registro de especies. En primer lugar, necesitamos contar los registros por año.\n\n\nUtilice las funciones group_by, summarize y filter para contar los registros de cada especie por año desde 1950 por cada técnica de muestreo (basisOfRecord)\n\n\nCode\ndat_per_year&lt;-dat_oso_danta_filtrado %&gt;% \n                group_by(year,basisOfRecord) %&gt;%\n                summarize(n = n()) %&gt;%\n                filter(year &gt; 1949)\n\n\nAhora podemos graficar los datos agrupando por técnica de muestro\n\n\nCode\np1&lt;-ggplot(dat_per_year, aes(x=year, y=n,color = basisOfRecord)) +\n    geom_line(linewidth = 1) \np1\n\n\n\n\n\n\n\n\n\nAñadir una línea en que muestre el año con más registros\n\n\nCode\np2&lt;-p1 +\n  geom_vline(xintercept = 2016,colour=\"black\", linetype = \"longdash\") \np2\n\n\n\n\n\n\n\n\n\nLa función anotate() nos permite añadir texto en ubicaciones específicas de nuestro gráfico\n\n\nCode\np3&lt;-p2 +\n  annotate(\"text\", label = \"2016\", x = 2017, y = 1300, size = 4, colour = \"black\")\np3\n\n\n\n\n\n\n\n\n\nFinalmente, podemos cambiar el tamaño del texto de los ejes\n\n\nCode\ne1&lt;-p3 +\n  theme_bw()+\n  theme(legend.position = \"right\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14),\n        text = element_text(size = 14),\n        axis.text.x = element_text(size = 12),\n        axis.text.y = element_text(size = 12))+\n    ylab(\"# registros\")+ xlab(\"año\")+\n  ggtitle(\"Número de registros de danta y oso\")\ne1"
  },
  {
    "objectID": "AM.html#citacion-adecuada-de-los-datos",
    "href": "AM.html#citacion-adecuada-de-los-datos",
    "title": "AM",
    "section": "",
    "text": "Tenga en cuenta que es una buena practica citar correctamente los datos que se descargan de GBIF.\n\n\nCode\n# get the DOIs for citing these data properly:\n\ngbif_citation(gbif_data_sp1) # para la danta\n\ngbif_citation(gbif_data_sp2) # para la el oso\n\n# nota: si necesita o prefiere solo un DOI para todo el conjunto de datos, descargue el conjunto de datos directamente desde www.gbif.org y luego importe el .csv a R. ¡Es muy importante citar correctamente las fuentes de datos! GBIF no es una fuente, sólo un depósito para muchas personas que trabajaron muy duro para recopilar estos datos y ponerlos a disposición.\n\n\n¡Hemos llegado al final de la mañana! Los conceptos aprendidos el día de hoy serán fundamentales para sacar el mayor provecho en la tarde. Es hora de Almorzar :)"
  },
  {
    "objectID": "ocupacion.html#salvador-mandujano",
    "href": "ocupacion.html#salvador-mandujano",
    "title": "Ocupación",
    "section": "Salvador Mandujano",
    "text": "Salvador Mandujano"
  },
  {
    "objectID": "ocupacion.html#section",
    "href": "ocupacion.html#section",
    "title": "Ocupación",
    "section": "",
    "text": "Tu turno!"
  },
  {
    "objectID": "ocupacion.html#section-1",
    "href": "ocupacion.html#section-1",
    "title": "Ocupación",
    "section": "",
    "text": "Tu turno!"
  },
  {
    "objectID": "ocupacion.html#allows-you-to-set-goals-and-to-monitor-them-over-time.",
    "href": "ocupacion.html#allows-you-to-set-goals-and-to-monitor-them-over-time.",
    "title": "Ocupación",
    "section": "Allows you to set goals and to monitor them over time.",
    "text": "Allows you to set goals and to monitor them over time."
  },
  {
    "objectID": "ocupacion.html#occupancy",
    "href": "ocupacion.html#occupancy",
    "title": "Ocupación",
    "section": "Occupancy",
    "text": "Occupancy\n\\[\\psi\\]"
  },
  {
    "objectID": "ocupacion.html#detection-probability",
    "href": "ocupacion.html#detection-probability",
    "title": "Ocupación",
    "section": "Detection probability",
    "text": "Detection probability\n\\[p\\]\n\nOccupancy is a reflection of other important population parameters such as density."
  },
  {
    "objectID": "ocupacion.html#which-one-should-i-use-the-maximum-likelihood-or-bayesian",
    "href": "ocupacion.html#which-one-should-i-use-the-maximum-likelihood-or-bayesian",
    "title": "Ocupación",
    "section": "Which one should I use? The maximum likelihood or Bayesian?",
    "text": "Which one should I use? The maximum likelihood or Bayesian?\nmaximum likelihood\n\nPackage unmarked\nIn R\nAdmits “automatic” model selection AIC\nProblems with many NAs\nHesian problem. estimates ok.\nDifficulty from 1 to 10: 3 if you already know R."
  },
  {
    "objectID": "ocupacion.html#which-one-should-i-use-the-maximum-likelihood-or-bayesian-1",
    "href": "ocupacion.html#which-one-should-i-use-the-maximum-likelihood-or-bayesian-1",
    "title": "Ocupación",
    "section": "Which one should I use? The maximum likelihood or Bayesian?",
    "text": "Which one should I use? The maximum likelihood or Bayesian?\nBayesian\n\nBUGS or Stan language, called from R - Model selection is not that easy, BIC is not suitable - You don’t have as many problems with many NAs in the matrix - Estimates are more accurate. - Difficulty from 1 to 10: 7 if you already know R.\nNew: Package UBMS"
  },
  {
    "objectID": "ocupacion.html#section-2",
    "href": "ocupacion.html#section-2",
    "title": "Ocupación",
    "section": "",
    "text": "Manos a la obra…"
  },
  {
    "objectID": "ocupacion.html#manos-a-la-obra",
    "href": "ocupacion.html#manos-a-la-obra",
    "title": "Ocupación",
    "section": "Manos a la obra",
    "text": "Manos a la obra"
  },
  {
    "objectID": "parte3.html",
    "href": "parte3.html",
    "title": "parte3",
    "section": "",
    "text": "Comenzamos cargando tres paquetes básicos necesarios para generar nuestros primeros modelos unmarked.\n\n\nCode\nlibrary(unmarked)\n\n\nModelo de Ocupación Diámico con datos simulados Primero generamos un conjunto de datos simple y simulado con valores específicos de año específicos para los parámetros, así como especificaciones de diseño, es decir, número de sitios, años y encuestas por año.\nLuego, veremos cómo ajustar un modelo de ocupación dinámico con dependencia del año en los parámetros de probabilidad de colonización, extinción y detección.\nSimulando, formateando y resumiendo datos Para simular los datos, ejecutamos el siguiente código R. Los valores reales para estos parámetros para cada año se extraen aleatoriamente de una distribución uniforme con los límites especificados.\n\n\nCode\nlibrary(maps)"
  },
  {
    "objectID": "parte3.html#modelando-la-ocupacion-de-un-venado-andino",
    "href": "parte3.html#modelando-la-ocupacion-de-un-venado-andino",
    "title": "parte3",
    "section": "",
    "text": "Comenzamos cargando tres paquetes básicos necesarios para generar nuestros primeros modelos unmarked.\n\n\nCode\nlibrary(unmarked)\n\n\nModelo de Ocupación Diámico con datos simulados Primero generamos un conjunto de datos simple y simulado con valores específicos de año específicos para los parámetros, así como especificaciones de diseño, es decir, número de sitios, años y encuestas por año.\nLuego, veremos cómo ajustar un modelo de ocupación dinámico con dependencia del año en los parámetros de probabilidad de colonización, extinción y detección.\nSimulando, formateando y resumiendo datos Para simular los datos, ejecutamos el siguiente código R. Los valores reales para estos parámetros para cada año se extraen aleatoriamente de una distribución uniforme con los límites especificados.\n\n\nCode\nlibrary(maps)"
  },
  {
    "objectID": "parte3.html#obtenga-ayuda",
    "href": "parte3.html#obtenga-ayuda",
    "title": "parte3",
    "section": "Obtenga ayuda",
    "text": "Obtenga ayuda\nEscribir código consiste en ensayo error y un 90% buscar la respuesta en Google.\nSi busca un problema en la web, como “ggplot remove legend”, normalmente obtendrá una respuesta bastante decente en Stack Overflow o en un sitio similar.\nSi la respuesta aún no existe en línea, regístrese en Stack Overflow y pregúntela usted mismo (pero primer dedique tiempo suficiente en buscar … ¡nadie quiere ser etiquetado por duplicar una pregunta existente!).\nOtra buena idea es buscar un grupo de apoyo local. El uso de R es una experiencia emocional, la curva de aprendizaje al comienzo es bien empinada, la frustración es común, pero luego de un tiempo la alegría de encontrar una solución puede ayudarnos a persistir. Tener a otras personas para ayudar, o simplemente escuchar sus frustraciones es una gran motivación para seguir aprendiendo R."
  },
  {
    "objectID": "parte3.html#package-citation",
    "href": "parte3.html#package-citation",
    "title": "parte3",
    "section": "Package Citation",
    "text": "Package Citation\n\n\nCode\npkgs &lt;- cite_packages(output = \"paragraph\", pkgs=\"Session\", out.dir = \".\")\n# knitr::kable(pkgs)\npkgs\n\n\nWe used R version 4.4.2 [@base] and the following R packages: maps v. 3.4.2.1 [@maps], unmarked v. 1.4.3 [@unmarked2011; @unmarked2023]."
  },
  {
    "objectID": "parte3.html#sesion-info",
    "href": "parte3.html#sesion-info",
    "title": "parte3",
    "section": "Sesion info",
    "text": "Sesion info\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nprint(sessionInfo(), locale = FALSE)\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] maps_3.4.2.1    unmarked_1.4.3  grateful_0.2.10\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.37     fastmap_1.2.0     xfun_0.49         lattice_0.22-6   \n [5] parallel_4.4.2    knitr_1.49        htmltools_0.5.8.1 rmarkdown_2.29   \n [9] cli_3.6.3         grid_4.4.2        compiler_4.4.2    rstudioapi_0.17.1\n[13] tools_4.4.2       evaluate_1.0.1    Rcpp_1.0.13-1     yaml_2.3.10      \n[17] rlang_1.1.4       jsonlite_1.8.9    htmlwidgets_1.6.4 MASS_7.3-61"
  },
  {
    "objectID": "parte2.html",
    "href": "parte2.html",
    "title": "parte2",
    "section": "",
    "text": "Los datos que vamos a usar provienen del articulo:\n\n\n\nElevation as an occupancy determinant of the little red brocket deer (Mazama rufina) in the Central Andes of Colombia. https://doi.org/10.15446/caldasia.v43n2.85449\n\n\n\n\nAcá evaluamos la influencia de variables del terreno sobre la ocupación del venado soche (Mazama rufina) en los Andes centrales de Colombia. La ocupación aumentó con la elevación hasta los 3000 m y por encima de este valor decrece. Esta información es crucial para predecir los posibles efectos del cambio climático sobre M. rufina y otras especies de montaña.\nComenzamos cargando tres paquetes básicos necesarios para generar mapas; mapview, sf y luego readr para leer los datos y unmarked para los modelos de ocupación.\n\n\nCode\nlibrary(mapview)\nlibrary(sf)\nlibrary(readr) # read csv\nlibrary(DT) # tablas en html\nlibrary(unmarked)\nlibrary(terra)\nlibrary(elevatr)\n\n\nEl paquete sf se utiliza para trabajar con datos espaciales y ofrece funciones para leer, escribir y analizar datos espaciales (features en inglés) de una manera sencilla y eficiente. Mapview nos permite visualizar mapas rapidamente en R.\n\n\nCode\nlibrary(maps)\n\n\n\n\n\n\nCode\n# read photo data in object y_full. Columns are days and rows sites\n# load(\"data/y_full.RData\") # if you got the repo in hard disk\nydata &lt;- \"https://github.com/dlizcano/Mazama_rufina/blob/main/data/y_full.RData?raw=true\"\nload(url(ydata))\n\n# read camera location\n# cams_loc_QR &lt;- read.csv(\"data/cams_location.csv\") # if you got the repo in hard disk\ncamdata &lt;- \"https://raw.githubusercontent.com/dlizcano/Mazama_rufina/main/data/cams_location.csv\"\ncams_loc_QR &lt;- read_csv(url(camdata))\n\n\n\n\n\nEn las columnas de y_full tenemos los dias de muestreo y en las filas cada uno de los sitios donde se instaló una camara trampa.\n\n\nCode\nView(y_full)\n\n\nEn la tabla cams_loc_QR tenemos las coordenadas de cada camara.\n\n\nCode\nView(cams_loc_QR)\n\n\n\n\n\nAhora vamos a usar las coordenadas de cada camara para obtener la elevación, la pendiente y el aspecto.\n\n\nCode\n# convert to sf\ncams_loc_QR_sf &lt;- st_as_sf(cams_loc_QR, coords = c(\"Longitud\", \"Latitud\"), crs = \"+proj=longlat +datum=WGS84 +no_defs\")\n# convert to UTM\ncams_loc_QR_sf_utm &lt;- st_transform(cams_loc_QR_sf, \"EPSG:32618\")\n\ncentroid &lt;- c(mean(cams_loc_QR$Longitud), mean(cams_loc_QR$Latitud))\n\n\n# clip_window &lt;- ext(-75.60 , -75.39, 4.59, 4.81) # extent\n# bb &lt;- c(-75.60, 4.59, -75.39,  4.81)\n\n# get spatial data as spatrast\nsrtm &lt;- rast(get_elev_raster(cams_loc_QR_sf_utm, z=9))\n\n# crop the  raster using the vector extent\nsrtm_crop &lt;- srtm #terra::crop(srtm, clip_window)\n\n# elevation.crop and terrain covs\nelevation &lt;- srtm_crop\nslope&lt;-terrain(srtm_crop, \"slope\", unit='degrees', neighbors=8)\naspect&lt;-terrain(srtm_crop, \"aspect\", unit='degrees', neighbors=8)\nroughness &lt;- terrain(srtm_crop, \"roughness\", neighbors=8)\n\ncov.list&lt;-list(elevation, slope, aspect, roughness)\ncov.stack&lt;-rast(cov.list)\nnames(cov.stack) &lt;- c(\"elevation\", \"slope\", \"aspect\", \"roughness\" )\nplot(cov.stack)"
  },
  {
    "objectID": "parte2.html#modelando-la-ocupacion-de-un-venado-andino",
    "href": "parte2.html#modelando-la-ocupacion-de-un-venado-andino",
    "title": "parte2",
    "section": "",
    "text": "Acá evaluamos la influencia de variables del terreno sobre la ocupación del venado soche (Mazama rufina) en los Andes centrales de Colombia. La ocupación aumentó con la elevación hasta los 3000 m y por encima de este valor decrece. Esta información es crucial para predecir los posibles efectos del cambio climático sobre M. rufina y otras especies de montaña.\nComenzamos cargando tres paquetes básicos necesarios para generar mapas; mapview, sf y luego readr para leer los datos y unmarked para los modelos de ocupación.\n\n\nCode\nlibrary(mapview)\nlibrary(sf)\nlibrary(readr) # read csv\nlibrary(DT) # tablas en html\nlibrary(unmarked)\nlibrary(terra)\nlibrary(elevatr)\n\n\nEl paquete sf se utiliza para trabajar con datos espaciales y ofrece funciones para leer, escribir y analizar datos espaciales (features en inglés) de una manera sencilla y eficiente. Mapview nos permite visualizar mapas rapidamente en R.\n\n\nCode\nlibrary(maps)\n\n\n\n\n\n\nCode\n# read photo data in object y_full. Columns are days and rows sites\n# load(\"data/y_full.RData\") # if you got the repo in hard disk\nydata &lt;- \"https://github.com/dlizcano/Mazama_rufina/blob/main/data/y_full.RData?raw=true\"\nload(url(ydata))\n\n# read camera location\n# cams_loc_QR &lt;- read.csv(\"data/cams_location.csv\") # if you got the repo in hard disk\ncamdata &lt;- \"https://raw.githubusercontent.com/dlizcano/Mazama_rufina/main/data/cams_location.csv\"\ncams_loc_QR &lt;- read_csv(url(camdata))\n\n\n\n\n\nEn las columnas de y_full tenemos los dias de muestreo y en las filas cada uno de los sitios donde se instaló una camara trampa.\n\n\nCode\nView(y_full)\n\n\nEn la tabla cams_loc_QR tenemos las coordenadas de cada camara.\n\n\nCode\nView(cams_loc_QR)\n\n\n\n\n\nAhora vamos a usar las coordenadas de cada camara para obtener la elevación, la pendiente y el aspecto.\n\n\nCode\n# convert to sf\ncams_loc_QR_sf &lt;- st_as_sf(cams_loc_QR, coords = c(\"Longitud\", \"Latitud\"), crs = \"+proj=longlat +datum=WGS84 +no_defs\")\n# convert to UTM\ncams_loc_QR_sf_utm &lt;- st_transform(cams_loc_QR_sf, \"EPSG:32618\")\n\ncentroid &lt;- c(mean(cams_loc_QR$Longitud), mean(cams_loc_QR$Latitud))\n\n\n# clip_window &lt;- ext(-75.60 , -75.39, 4.59, 4.81) # extent\n# bb &lt;- c(-75.60, 4.59, -75.39,  4.81)\n\n# get spatial data as spatrast\nsrtm &lt;- rast(get_elev_raster(cams_loc_QR_sf_utm, z=9))\n\n# crop the  raster using the vector extent\nsrtm_crop &lt;- srtm #terra::crop(srtm, clip_window)\n\n# elevation.crop and terrain covs\nelevation &lt;- srtm_crop\nslope&lt;-terrain(srtm_crop, \"slope\", unit='degrees', neighbors=8)\naspect&lt;-terrain(srtm_crop, \"aspect\", unit='degrees', neighbors=8)\nroughness &lt;- terrain(srtm_crop, \"roughness\", neighbors=8)\n\ncov.list&lt;-list(elevation, slope, aspect, roughness)\ncov.stack&lt;-rast(cov.list)\nnames(cov.stack) &lt;- c(\"elevation\", \"slope\", \"aspect\", \"roughness\" )\nplot(cov.stack)"
  },
  {
    "objectID": "parte2.html#obtenga-ayuda",
    "href": "parte2.html#obtenga-ayuda",
    "title": "parte2",
    "section": "Obtenga ayuda",
    "text": "Obtenga ayuda\nEscribir código consiste en ensayo error y un 90% buscar la respuesta en Google.\nSi busca un problema en la web, como “ggplot remove legend”, normalmente obtendrá una respuesta bastante decente en Stack Overflow o en un sitio similar.\nSi la respuesta aún no existe en línea, regístrese en Stack Overflow y pregúntela usted mismo (pero primer dedique tiempo suficiente en buscar … ¡nadie quiere ser etiquetado por duplicar una pregunta existente!).\nOtra buena idea es buscar un grupo de apoyo local. El uso de R es una experiencia emocional, la curva de aprendizaje al comienzo es bien empinada, la frustración es común, pero luego de un tiempo la alegría de encontrar una solución puede ayudarnos a persistir. Tener a otras personas para ayudar, o simplemente escuchar sus frustraciones es una gran motivación para seguir aprendiendo R."
  },
  {
    "objectID": "parte2.html#package-citation",
    "href": "parte2.html#package-citation",
    "title": "parte2",
    "section": "Package Citation",
    "text": "Package Citation\n\n\nCode\npkgs &lt;- cite_packages(output = \"paragraph\", pkgs=\"Session\", out.dir = \".\")\n# knitr::kable(pkgs)\npkgs\n\n\nWe used R version 4.4.2 [@base] and the following R packages: DT v. 0.33 [@DT], elevatr v. 0.99.0 [@elevatr], maps v. 3.4.2.1 [@maps], mapview v. 2.11.2 [@mapview], RColorBrewer v. 1.1.3 [@RColorBrewer], sf v. 1.0.19 [@sf2018; @sf2023], terra v. 1.8.21 [@terra], tidyverse v. 2.0.0 [@tidyverse], unmarked v. 1.4.3 [@unmarked2011; @unmarked2023]."
  },
  {
    "objectID": "parte2.html#sesion-info",
    "href": "parte2.html#sesion-info",
    "title": "parte2",
    "section": "Sesion info",
    "text": "Sesion info\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nprint(sessionInfo(), locale = FALSE)\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] RColorBrewer_1.1-3 maps_3.4.2.1       elevatr_0.99.0     terra_1.8-21      \n [5] unmarked_1.4.3     DT_0.33            readr_2.1.5        sf_1.0-19         \n [9] mapview_2.11.2     grateful_0.2.10   \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.1        farver_2.1.2            fastmap_1.2.0          \n [4] leaflet_2.2.2           digest_0.6.37           lifecycle_1.0.4        \n [7] magrittr_2.0.3          compiler_4.4.2          rlang_1.1.4            \n[10] sass_0.4.9              progress_1.2.3          tools_4.4.2            \n[13] yaml_2.3.10             knitr_1.49              prettyunits_1.2.0      \n[16] htmlwidgets_1.6.4       bit_4.5.0.1             sp_2.1-4               \n[19] classInt_0.4-10         curl_6.0.0              abind_1.4-8            \n[22] KernSmooth_2.23-24      purrr_1.0.2             grid_4.4.2             \n[25] stats4_4.4.2            e1071_1.7-16            leafem_0.2.3           \n[28] colorspace_2.1-1        progressr_0.15.0        scales_1.3.0           \n[31] MASS_7.3-61             cli_3.6.3               rmarkdown_2.29         \n[34] crayon_1.5.3            rstudioapi_0.17.1       httr_1.4.7             \n[37] tzdb_0.4.0              minqa_1.2.8             DBI_1.2.3              \n[40] pbapply_1.7-2           cachem_1.1.0            proxy_0.4-27           \n[43] splines_4.4.2           stars_0.6-8             slippymath_0.3.1       \n[46] parallel_4.4.2          base64enc_0.1-3         vctrs_0.6.5            \n[49] boot_1.3-31             Matrix_1.7-1            jsonlite_1.8.9         \n[52] hms_1.1.3               bit64_4.5.2             crosstalk_1.2.1        \n[55] jquerylib_0.1.4         units_0.8-5             glue_1.8.0             \n[58] nloptr_2.1.1            leaflet.providers_2.0.0 codetools_0.2-20       \n[61] raster_3.6-30           lme4_1.1-35.5           munsell_0.5.1          \n[64] tibble_3.2.1            pillar_1.10.1           htmltools_0.5.8.1      \n[67] satellite_1.0.5         R6_2.6.1                vroom_1.6.5            \n[70] evaluate_1.0.1          lattice_0.22-6          png_0.1-8              \n[73] bslib_0.8.0             class_7.3-22            Rcpp_1.0.13-1          \n[76] nlme_3.1-166            xfun_0.49               pkgconfig_2.0.3"
  },
  {
    "objectID": "parte1.html",
    "href": "parte1.html",
    "title": "parte1",
    "section": "",
    "text": "En primer lugar, es importante recordar que la organización es clave cuando se está generando un nuevo código. En este sentido, le recomendamos que cree una carpeta en su disco duro (C:) para cada nuevo proyecto. Puede hacer esto como un proyecto de Rstudio; para esto diríjase a: Archivo&gt; Nuevo proyecto o simplemente cree una nueva carpeta en su explorador y establezca su directorio de trabajo allí. Dentro de esta carpeta, cree una carpeta de datos donde guardará sus datos sin procesar. Puede almacenar algunos objetos intermedios en otra subcarpeta. También cree una carpeta para su código R y una carpeta para guardar sus figuras.\nla organización de carpetas que se sugere es:\nC://curso\n- data\n- R\n- fig"
  },
  {
    "objectID": "parte1.html#antes-de-comenzar",
    "href": "parte1.html#antes-de-comenzar",
    "title": "parte1",
    "section": "",
    "text": "En primer lugar, es importante recordar que la organización es clave cuando se está generando un nuevo código. En este sentido, le recomendamos que cree una carpeta en su disco duro (C:) para cada nuevo proyecto. Puede hacer esto como un proyecto de Rstudio; para esto diríjase a: Archivo&gt; Nuevo proyecto o simplemente cree una nueva carpeta en su explorador y establezca su directorio de trabajo allí. Dentro de esta carpeta, cree una carpeta de datos donde guardará sus datos sin procesar. Puede almacenar algunos objetos intermedios en otra subcarpeta. También cree una carpeta para su código R y una carpeta para guardar sus figuras.\nla organización de carpetas que se sugere es:\nC://curso\n- data\n- R\n- fig"
  },
  {
    "objectID": "parte1.html#objetivo",
    "href": "parte1.html#objetivo",
    "title": "parte1",
    "section": "Objetivo",
    "text": "Objetivo\nPresentar una introducción a los conceptos de monitoreo de biodiversidad usando modelos de ocupación, con estimadores de máxima verosimilitud y bayesianos.\n\nPrerrequisitos\nConocimientos de estadística básica (probabilidad y regresiones), manejo básico de R (objetos, vectores, data frame, matrices y funciones). Es importante que los participantes estén familiarizados con R.\n\n\nIntroducción (Teórico, 1 horas)\nEl problema de contar organismos en ecología, censos, muestreos, poblaciones y tamaño poblacional. La densidad, la abundancia y la ocupación.\n\nTenga en cuenta que se requiere conexión a internet y que podemos estar descargando algunos datos desde GitHub…"
  },
  {
    "objectID": "parte1.html#package-citation",
    "href": "parte1.html#package-citation",
    "title": "parte1",
    "section": "Package Citation",
    "text": "Package Citation\n\n\nCode\npkgs &lt;- cite_packages(output = \"paragraph\", pkgs=\"Session\", out.dir = \".\")\n# knitr::kable(pkgs)\npkgs\n\n\nWe used R version 4.4.2 [@base] and the following R packages: ."
  },
  {
    "objectID": "parte1.html#sesion-info",
    "href": "parte1.html#sesion-info",
    "title": "parte1",
    "section": "Sesion info",
    "text": "Sesion info\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nprint(sessionInfo(), locale = FALSE)\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] grateful_0.2.10\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.3        \n [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_1.8.9    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.4       evaluate_1.0.1"
  },
  {
    "objectID": "index.html#package-citation",
    "href": "index.html#package-citation",
    "title": "Modelado de la Ocupación, abundancia y densidad de poblaciones",
    "section": "Package Citation",
    "text": "Package Citation\n\ncodigo R\npkgs &lt;- cite_packages(output = \"paragraph\", pkgs=\"Session\", out.dir = \".\")\n# knitr::kable(pkgs)\npkgs\n\nWe used R version 4.4.2 [@base] and the following R packages: ."
  },
  {
    "objectID": "index.html#sesion-info",
    "href": "index.html#sesion-info",
    "title": "Modelado de la Ocupación, abundancia y densidad de poblaciones",
    "section": "Sesion info",
    "text": "Sesion info\n\n\n\n\n\n\nNote\n\n\n\n\n\n\ncodigo R\nprint(sessionInfo(), locale = FALSE)\n\nR version 4.4.2 (2024-10-31 ucrt) Platform: x86_64-w64-mingw32/x64 Running under: Windows 10 x64 (build 19045)\nMatrix products: default\nattached base packages: [1] stats graphics grDevices utils datasets methods base\nother attached packages: [1] grateful_0.2.10\nloaded via a namespace (and not attached): [1] htmlwidgets_1.6.4 compiler_4.4.2 fastmap_1.2.0 cli_3.6.3\n[5] tools_4.4.2 htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10\n[9] rmarkdown_2.29 knitr_1.49 jsonlite_1.8.9 xfun_0.49\n[13] digest_0.6.37 rlang_1.1.4 evaluate_1.0.1"
  },
  {
    "objectID": "parte2.html#objeto-umf",
    "href": "parte2.html#objeto-umf",
    "title": "parte2",
    "section": "objeto umf",
    "text": "objeto umf\n\n#############\n# Occu analisys\n\n# Make unmarked frame\numf_y_full&lt;- unmarkedFrameOccu(y= y_full[,1:108])\nsiteCovs(umf_y_full) &lt;- full_covs_s # data.frame(Elev=full_covs$Elev) # Full\n#######Graficar umf\nplot(umf_y_full)"
  },
  {
    "objectID": "parte2.html#posibles-modelos",
    "href": "parte2.html#posibles-modelos",
    "title": "parte2",
    "section": "Posibles modelos",
    "text": "Posibles modelos\n\n# build  models\nmf0&lt;-occu(~1 ~ 1, umf_y_full)\nmf1&lt;-occu(~1 ~ elevation, umf_y_full)\nmf2&lt;-occu(~1 ~ elevation +I(elevation^2), umf_y_full)\nmf3&lt;-occu(~1 ~ slope, umf_y_full)\nmf4&lt;-occu(~1 ~ aspect, umf_y_full)\nmf5&lt;-occu(~1 ~ roughness, umf_y_full, starts = c(0.6, -3, 0))\nmf6&lt;-occu(~elevation +I(elevation^2) ~ elevation +I(elevation^2), umf_y_full)\nmf7&lt;-occu(~roughness ~ elevation +I(elevation^2), umf_y_full)\nmf8&lt;-occu(~slope ~ elevation +I(elevation^2), umf_y_full)\n\n\n# fit list\nfms1&lt;-fitList(\"p(.) Ocu(.)\"=mf0,\n              \"p(.) Ocu(elev)\"=mf1,\n              \"p(.) Ocu(elev^2)\"=mf2,\n              \"p(.) Ocu(slope)\"=mf3,\n              \"p(.) Ocu(aspect)\"=mf4,\n              \"p(.) Ocu(roughness)\"=mf5,\n              \"p(elev^2) Ocu(elev^2)\"=mf6,\n              \"p(roughness) Ocu(elev^2)\"=mf7,\n              \"p(slope) Ocu(elev^2)\"=mf8\n)\n\n\nmodSel(fms1)\n\nWarning in sqrt(diag(vcov(x, altNames = TRUE))): Se han producido NaNs\n\n\n                         nPars    AIC delta   AICwt cumltvWt\np(.) Ocu(elev^2)             4 366.56  0.00 4.0e-01     0.40\np(roughness) Ocu(elev^2)     5 368.18  1.61 1.8e-01     0.57\np(slope) Ocu(elev^2)         5 368.40  1.83 1.6e-01     0.73\np(.) Ocu(aspect)             3 369.19  2.62 1.1e-01     0.84\np(.) Ocu(elev)               3 369.31  2.74 1.0e-01     0.94\np(elev^2) Ocu(elev^2)        6 370.40  3.84 5.8e-02     1.00\np(.) Ocu(slope)              3 376.97 10.41 2.2e-03     1.00\np(.) Ocu(roughness)          3 377.77 11.21 1.5e-03     1.00\np(.) Ocu(.)                  2 417.05 50.49 4.3e-12     1.00"
  },
  {
    "objectID": "parte2.html#bondad-de-ajuste",
    "href": "parte2.html#bondad-de-ajuste",
    "title": "parte2",
    "section": "Bondad de ajuste",
    "text": "Bondad de ajuste\n\n# print(fms1)\n\npb_f &lt;- parboot(mf7, nsim=500, report=10) \n\nWarning: report argument is non-functional and will be deprecated in the next\nversion"
  },
  {
    "objectID": "parte2.html#plot-detección-en-escala-original",
    "href": "parte2.html#plot-detección-en-escala-original",
    "title": "parte2",
    "section": "plot Detección en escala original",
    "text": "plot Detección en escala original\n\nnewdat_range&lt;-data.frame(elevation=seq(min(full_covs_s$elevation),\n                                       max(full_covs_s$elevation),length=100), \n                         roughness=seq(min(full_covs_s$roughness),\n                                       max(full_covs_s$roughness), length=100))\n\n\npred_det &lt;-predict(mf7, type=\"det\", newdata=newdat_range, appendData=TRUE)\n\n\n\n## plot Detection en escala original\npred_det &lt;-predict(mf7, type=\"det\", newdata=newdat_range, appendData=TRUE)\nplot(Predicted~roughness, pred_det,type=\"l\",col=\"blue\", \n     xlab=\"Roughness\",\n     ylab=\"Detection Probability\",\n     xaxt=\"n\")\nxticks &lt;- c(-1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5, 3) # -1:2\nxlabs &lt;- xticks*sd(full_covs$roughness) + mean(full_covs$roughness) #Use the mean and sd of original value to change label name\naxis(1, at=xticks, labels=round(xlabs, 1))\nlines(lower~roughness, pred_det,type=\"l\",col=gray(0.5))\nlines(upper~roughness, pred_det,type=\"l\",col=gray(0.5))"
  },
  {
    "objectID": "parte2.html#plot-ocupación-en-escala-original",
    "href": "parte2.html#plot-ocupación-en-escala-original",
    "title": "parte2",
    "section": "Plot Ocupación en escala original",
    "text": "Plot Ocupación en escala original\n\npred_psi &lt;-predict(mf7, type=\"state\", newdata=newdat_range, appendData=TRUE) \n\n\n###  Plot occupancy en escala original\nplot(Predicted ~ elevation, pred_psi, type=\"l\", ylim=c(0,1), col=\"blue\",\n     xlab=\"Elevation\",\n     ylab=\"Occupancy Probability\",\n     xaxt=\"n\")\nxticks &lt;- c(-1, -0.5, 0, 0.5, 1, 1.5, 2)  # -1:2\nxlabs &lt;- xticks*sd(full_covs$elevation) + mean(full_covs$elevation) #Use the mean and sd of original value to change label name\naxis(1, at=xticks, labels=round(xlabs, 1))\nlines(lower ~ elevation, pred_psi, type=\"l\", col=gray(0.5))\nlines(upper ~ elevation, pred_psi, type=\"l\", col=gray(0.5))"
  },
  {
    "objectID": "parte2.html#modelo-espacialmente-explícito",
    "href": "parte2.html#modelo-espacialmente-explícito",
    "title": "parte2",
    "section": "Modelo espacialmente explícito",
    "text": "Modelo espacialmente explícito\n\npredict\n\nlibrary(RColorBrewer)\n\nsrtm_crop_s &lt;- rast(list(scale(elevation), \n                     scale(roughness))) # scale altitud\nnames(srtm_crop_s) &lt;- c(\"elevation\", \"roughness\")\n# crs(srtm_crop_s) &lt;- \"+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0\"\n\npred_p_s &lt;-predict(mf7, type=\"det\", newdata=srtm_crop_s) \npred_psi_s &lt;-predict(mf7, type=\"state\", newdata=srtm_crop_s) \n\n\n\nPlot\n\nconvert to original scale\n\npred_p_r &lt;- pred_p_s * sd(full_covs$roughness) + mean(full_covs$roughness)\n\n\npred_psi_r &lt;- pred_psi_s * sd(full_covs$roughness) + mean(full_covs$roughness)\n\n\n# w &lt;- project(pred_p_r, \"EPSG:32618\")\n# clr &lt;- colorRampPalette(brewer.pal(9, \"YlGn\"))\n\n\n\nDetection\n\nmapview (pred_p_r[[1]])\n\n\n\n\n\n\n\nOccupancy\n\nmapview (pred_psi_r[[1]])"
  },
  {
    "objectID": "about.html#instructor",
    "href": "about.html#instructor",
    "title": "About",
    "section": "",
    "text": "Diego J. Lizcano, Ph.D.. Wildlife Conservation Society (WCS) y Sociedad Colombiana de Mastozoología (SCMas)"
  },
  {
    "objectID": "about.html#material-de-apoyo-adicional",
    "href": "about.html#material-de-apoyo-adicional",
    "title": "About",
    "section": "Material de apoyo adicional:",
    "text": "Material de apoyo adicional:\nAndrade-Ponce, G., Cepeda-Duque, J. C., Mandujano, S., Velásquez-C, K. L., Lizcano, D. J., & Gómez-Valencia, B. (2021). Modelos de ocupación para datos de cámaras trampa. Mammalogy Notes, 7(1), 200. https://doi.org/10.47603/mano.v7n1.200\nLizcano DJ. 2020. Simulación y análisis de ocupación. Entendiendo las simulaciones y el modelo básico de ocupación. Versión 1. http://doi.org/10.5281/zenodo.4028019"
  }
]